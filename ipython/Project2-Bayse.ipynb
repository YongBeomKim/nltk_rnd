{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# **나이브베이즈 모델의 활용**\n",
    "1. **베이지안 평가 학습모델**을 불러온다 (0:부정 / 1:긍정)\n",
    "1. **분석을 위한 네이버 뉴스 댓글**을 수집한다 (600개 내외가 적합)\n",
    "1. **긍정/ 부정 댓글**을 분류한다\n",
    "1. **긍정 리뷰**의 **Token** 을 트위터 **Stemming**으로 정규화 한다\n",
    "1. **정규화된 Token** 중 **\"명사\", \"동사\", \"형용사\"** 만 수집\n",
    "1. 수집된 Token List 객체를 **nltk.Text 로 변환 후 빈도상위 10개**를 출력한다\n",
    "\n",
    "<img src=\"http://www.meconomynews.com/news/photo/201806/15255_14549_2116.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **1 모듈과 데이터 불러오기**\n",
    "Import Data / Datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 1 : 앞에서 학습한 Classifier 모델을 불러온다\n",
    "# >> './data/classifiers.model' --> classifier\n",
    "import pickle\n",
    "classifier = \"=Quiz!=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 2 : 분류기준 단어목록 불러오기\n",
    "# >> './data/selected.words' --> selected_words\n",
    "selected_words = \"=Quiz!=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer 생성/ 판단모듈\n",
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "\n",
    "# 문단을 긍부정 분석용 Token 생성하기\n",
    "def tokenize(doc):\n",
    "    doc = ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "    return {'exists({})'.format(word): (word in set(doc)) for word in selected_words}\n",
    "\n",
    "# 위에서 생성한 Token을 활용하여 판단하기\n",
    "def classify_text(text):\n",
    "    tokens = tokenize(text)             # 트위터로 Stemming/ Taggging 후 Selected_word 판단결과 객체\n",
    "    return classifier.classify(tokens)  # 분류모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터와 모델, 함수를 활용하여 긍/부정 Test\n",
    "# 0 : 부정모델 , 1 : 긍정모델\n",
    "\n",
    "text   = \"\"\"영화가 재미있어요\"\"\"\n",
    "\n",
    "# 학습 데이터를 활용하여 text 내용 긍/부정 판단\n",
    "result = classify_text(text)\n",
    "if result == '1': \n",
    "    print('긍정리뷰')\n",
    "else:             \n",
    "    print('부정리뷰')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **2 뉴스 데이터 댓글데이터 불러오기**\n",
    "replies [참고](http://blog.naver.com/PostView.nhn?blogId=sangdo14&logNo=220610607049&categoryNo=0&parentCategoryNo=163&viewDate=&currentPage=1&postListTopCurrentPage=1&from=search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외부뉴스 데이터 수집하기\n",
    "from txtutil import Naver_news_rep\n",
    "# news_url = \"https://news.naver.com/main/hotissue/read.nhn?mid=hot&\" +\\\n",
    "#            \"sid1=&cid=1064721&iid=3227816&oid=001&aid=0010068060&ptype=021\"\n",
    "# replies  = Naver_news_rep(news_url)\n",
    "\n",
    "# import pickle\n",
    "# pickle.dump(replies, open('./data/naver_news.rep', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 3 : 네이버 뉴스 댓글 저장데이터 불러오기\n",
    "# >> './data/naver_news.rep' --> data\n",
    "\n",
    "import pickle\n",
    "data = pickle.load(open('./data/naver_news.rep', 'rb'))\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **3 댓글자료를 긍정 부정 분류**\n",
    "result['긍정'] / result['부정'] dict 객체로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 댓글 갯수중 긍정/ 부정 갯수 계산하기\n",
    "pro, con = [], []\n",
    "for datum in data:\n",
    "    if classify_text(datum) == \"1\":\n",
    "        pro.append(datum)\n",
    "    else:\n",
    "        con.append(datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정 / 부정 분류된 데이터를 Json 과 같은 형태로 정리\n",
    "result = {}\n",
    "result[\"긍정\"] = pro\n",
    "result[\"부정\"] = con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정리뷰 갯수\n",
    "len(result[\"긍정\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부정리뷰 갯수\n",
    "len(result[\"부정\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## **4 \"부정분류\"된 댓글의 자연어 분석**\n",
    "result['긍정'] / result['부정'] dict 객체로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긍정 댓글을 구분하여 분류한 뒤\n",
    "# 명사, 형용사, 동사 Token만 추출하기 (전처리 / Token의 예외처리는 미포함)\n",
    "texts = result['부정']\n",
    "texts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filtered_tokens = \"\"\n",
    "\n",
    "# 명사, 형용사, 동사 Filtering\n",
    "for text in texts:\n",
    "    for txt in text[0].split(' '):\n",
    "        tokens = twitter.pos(text ,stem=True)\n",
    "        tokens = [token[0]    for token in tokens    \n",
    "                              if (token[1] in ['Noun','Adjective','Verb']) and (len(token[0]) > 1 )]\n",
    "        tokens = \" \".join(tokens)\n",
    "        filtered_tokens += tokens\n",
    "        \n",
    "print(filtered_tokens[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "filtered_tokens = word_tokenize(filtered_tokens)\n",
    "\n",
    "# nltk.Text() 객체를 활용\n",
    "# 상위 빈도수 20인 Token을 추출\n",
    "import nltk\n",
    "pos_nltk = nltk.Text(filtered_tokens, name='부정댓글')\n",
    "pos_nltk.vocab().most_common(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
